URL: https://docs.python.org/3/reference/datamodel.html

Title: 3. Data model — Python 3.5.2 documentation

Doc Id: 276

Meta Tags : No meta tag found in document

Date :Jun 27, 2016

Content :Objects are Python’s abstraction for data.  All data in a Python program
is represented by objects or by relations between objects. (In a sense, and in
conformance to Von Neumann’s model of a “stored program computer,” code is also
represented by objects.)
Every object has an identity, a type and a value.  An object’s identity never
changes once it has been created; you may think of it as the object’s address in
memory.  The ‘is‘ operator compares the identity of two objects; the
id() function returns an integer representing its identity.
CPython implementation detail: For CPython, id(x) is the memory address where x is stored.
An object’s type determines the operations that the object supports (e.g., “does
it have a length?”) and also defines the possible values for objects of that
type.  The type() function returns an object’s type (which is an object
itself).  Like its identity, an object’s type is also unchangeable.
[1]
The value of some objects can change.  Objects whose value can
change are said to be mutable; objects whose value is unchangeable once they
are created are called immutable. (The value of an immutable container object
that contains a reference to a mutable object can change when the latter’s value
is changed; however the container is still considered immutable, because the
collection of objects it contains cannot be changed.  So, immutability is not
strictly the same as having an unchangeable value, it is more subtle.) An
object’s mutability is determined by its type; for instance, numbers, strings
and tuples are immutable, while dictionaries and lists are mutable.
Objects are never explicitly destroyed; however, when they become unreachable
they may be garbage-collected.  An implementation is allowed to postpone garbage
collection or omit it altogether — it is a matter of implementation quality
how garbage collection is implemented, as long as no objects are collected that
are still reachable.
CPython implementation detail: CPython currently uses a reference-counting scheme with (optional) delayed
detection of cyclically linked garbage, which collects most objects as soon
as they become unreachable, but is not guaranteed to collect garbage
containing circular references.  See the documentation of the gc
module for information on controlling the collection of cyclic garbage.
Other implementations act differently and CPython may change.
Do not depend on immediate finalization of objects when they become
unreachable (so you should always close files explicitly).
Note that the use of the implementation’s tracing or debugging facilities may
keep objects alive that would normally be collectable. Also note that catching
an exception with a ‘try...except‘ statement may keep
objects alive.
Some objects contain references to “external” resources such as open files or
windows.  It is understood that these resources are freed when the object is
garbage-collected, but since garbage collection is not guaranteed to happen,
such objects also provide an explicit way to release the external resource,
usually a close() method. Programs are strongly recommended to explicitly
close such objects.  The ‘try...finally‘ statement
and the ‘with‘ statement provide convenient ways to do this.
Some objects contain references to other objects; these are called containers.
Examples of containers are tuples, lists and dictionaries.  The references are
part of a container’s value.  In most cases, when we talk about the value of a
container, we imply the values, not the identities of the contained objects;
however, when we talk about the mutability of a container, only the identities
of the immediately contained objects are implied.  So, if an immutable container
(like a tuple) contains a reference to a mutable object, its value changes if
that mutable object is changed.
Types affect almost all aspects of object behavior.  Even the importance of
object identity is affected in some sense: for immutable types, operations that
compute new values may actually return a reference to any existing object with
the same type and value, while for mutable objects this is not allowed.  E.g.,
after a = 1; b = 1, a and b may or may not refer to the same object
with the value one, depending on the implementation, but after c = []; d =
[], c and d are guaranteed to refer to two different, unique, newly
created empty lists. (Note that c = d = [] assigns the same object to both
c and d.)
Below is a list of the types that are built into Python.  Extension modules
(written in C, Java, or other languages, depending on the implementation) can
define additional types.  Future versions of Python may add types to the type
hierarchy (e.g., rational numbers, efficiently stored arrays of integers, etc.),
although such additions will often be provided via the standard library instead.
Some of the type descriptions below contain a paragraph listing ‘special
attributes.’  These are attributes that provide access to the implementation and
are not intended for general use.  Their definition may change in the future.
This type has a single value.  There is a single object with this value. This
object is accessed through the built-in name None. It is used to signify the
absence of a value in many situations, e.g., it is returned from functions that
don’t explicitly return anything. Its truth value is false.
This type has a single value.  There is a single object with this value. This
object is accessed through the built-in name NotImplemented. Numeric methods
and rich comparison methods should return this value if they do not implement the
operation for the operands provided.  (The interpreter will then try the
reflected operation, or some other fallback, depending on the operator.)  Its
truth value is true.
See
Implementing the arithmetic operations
for more details.
This type has a single value.  There is a single object with this value. This
object is accessed through the literal ... or the built-in name
Ellipsis.  Its truth value is true.
These are created by numeric literals and returned as results by arithmetic
operators and arithmetic built-in functions.  Numeric objects are immutable;
once created their value never changes.  Python numbers are of course strongly
related to mathematical numbers, but subject to the limitations of numerical
representation in computers.
Python distinguishes between integers, floating point numbers, and complex
numbers:
These represent elements from the mathematical set of integers (positive and
negative).
There are two types of integers:
Integers (int)
These represent the truth values False and True.  The two objects representing
the values False and True are the only Boolean objects. The Boolean type is a
subtype of the integer type, and Boolean values behave like the values 0 and 1,
respectively, in almost all contexts, the exception being that when converted to
a string, the strings "False" or "True" are returned, respectively.
The rules for integer representation are intended to give the most meaningful
interpretation of shift and mask operations involving negative integers.
These represent machine-level double precision floating point numbers. You are
at the mercy of the underlying machine architecture (and C or Java
implementation) for the accepted range and handling of overflow. Python does not
support single-precision floating point numbers; the savings in processor and
memory usage that are usually the reason for using these are dwarfed by the
overhead of using objects in Python, so there is no reason to complicate the
language with two kinds of floating point numbers.
These represent complex numbers as a pair of machine-level double precision
floating point numbers.  The same caveats apply as for floating point numbers.
The real and imaginary parts of a complex number z can be retrieved through
the read-only attributes z.real and z.imag.
These represent finite ordered sets indexed by non-negative numbers. The
built-in function len() returns the number of items of a sequence. When
the length of a sequence is n, the index set contains the numbers 0, 1,
..., n-1.  Item i of sequence a is selected by a[i].
Sequences also support slicing: a[i:j] selects all items with index k such
that i <= k < j.  When used as an expression, a slice is a
sequence of the same type.  This implies that the index set is renumbered so
that it starts at 0.
Some sequences also support “extended slicing” with a third “step” parameter:
a[i:j:k] selects all items of a with index x where x = i + n*k, n
>= 0 and i <= x < j.
Sequences are distinguished according to their mutability:
An object of an immutable sequence type cannot change once it is created.  (If
the object contains references to other objects, these other objects may be
mutable and may be changed; however, the collection of objects directly
referenced by an immutable object cannot change.)
The following types are immutable sequences:
A string is a sequence of values that represent Unicode code points.
All the code points in the range U+0000 - U+10FFFF can be
represented in a string.  Python doesn’t have a char type;
instead, every code point in the string is represented as a string
object with length 1.  The built-in function ord()
converts a code point from its string form to an integer in the
range 0 - 10FFFF; chr() converts an integer in the range
0 - 10FFFF to the corresponding length 1 string object.
str.encode() can be used to convert a str to
bytes using the given text encoding, and
bytes.decode() can be used to achieve the opposite.
The items of a tuple are arbitrary Python objects. Tuples of two or
more items are formed by comma-separated lists of expressions.  A tuple
of one item (a ‘singleton’) can be formed by affixing a comma to an
expression (an expression by itself does not create a tuple, since
parentheses must be usable for grouping of expressions).  An empty
tuple can be formed by an empty pair of parentheses.
A bytes object is an immutable array.  The items are 8-bit bytes,
represented by integers in the range 0 <= x < 256.  Bytes literals
(like b'abc') and the built-in function bytes() can be used to
construct bytes objects.  Also, bytes objects can be decoded to strings
via the decode() method.
Mutable sequences can be changed after they are created.  The subscription and
slicing notations can be used as the target of assignment and del
(delete) statements.
There are currently two intrinsic mutable sequence types:
The items of a list are arbitrary Python objects.  Lists are formed by
placing a comma-separated list of expressions in square brackets. (Note
that there are no special cases needed to form lists of length 0 or 1.)
A bytearray object is a mutable array. They are created by the built-in
bytearray() constructor.  Aside from being mutable (and hence
unhashable), byte arrays otherwise provide the same interface and
functionality as immutable bytes objects.
The extension module array provides an additional example of a
mutable sequence type, as does the collections module.
These represent unordered, finite sets of unique, immutable objects. As such,
they cannot be indexed by any subscript. However, they can be iterated over, and
the built-in function len() returns the number of items in a set. Common
uses for sets are fast membership testing, removing duplicates from a sequence,
and computing mathematical operations such as intersection, union, difference,
and symmetric difference.
For set elements, the same immutability rules apply as for dictionary keys. Note
that numeric types obey the normal rules for numeric comparison: if two numbers
compare equal (e.g., 1 and 1.0), only one of them can be contained in a
set.
There are currently two intrinsic set types:
These represent a mutable set. They are created by the built-in set()
constructor and can be modified afterwards by several methods, such as
add().
These represent an immutable set.  They are created by the built-in
frozenset() constructor.  As a frozenset is immutable and
hashable, it can be used again as an element of another set, or as
a dictionary key.
These represent finite sets of objects indexed by arbitrary index sets. The
subscript notation a[k] selects the item indexed by k from the mapping
a; this can be used in expressions and as the target of assignments or
del statements. The built-in function len() returns the number
of items in a mapping.
There is currently a single intrinsic mapping type:
These represent finite sets of objects indexed by nearly arbitrary values.  The
only types of values not acceptable as keys are values containing lists or
dictionaries or other mutable types that are compared by value rather than by
object identity, the reason being that the efficient implementation of
dictionaries requires a key’s hash value to remain constant. Numeric types used
for keys obey the normal rules for numeric comparison: if two numbers compare
equal (e.g., 1 and 1.0) then they can be used interchangeably to index
the same dictionary entry.
Dictionaries are mutable; they can be created by the {...} notation (see
section Dictionary displays).
The extension modules dbm.ndbm and dbm.gnu provide
additional examples of mapping types, as does the collections
module.
These are the types to which the function call operation (see section
Calls) can be applied:
A user-defined function object is created by a function definition (see
section Function definitions).  It should be called with an argument list
containing the same number of items as the function’s formal parameter
list.
Special attributes:
The function’s
qualified name
New in version 3.3.
Most of the attributes labelled “Writable” check the type of the assigned value.
Function objects also support getting and setting arbitrary attributes, which
can be used, for example, to attach metadata to functions.  Regular attribute
dot-notation is used to get and set such attributes. Note that the current
implementation only supports function attributes on user-defined functions.
Function attributes on built-in functions may be supported in the future.
Additional information about a function’s definition can be retrieved from its
code object; see the description of internal types below.
An instance method object combines a class, a class instance and any
callable object (normally a user-defined function).
Special read-only attributes: __self__ is the class instance object,
__func__ is the function object; __doc__ is the method’s
documentation (same as __func__.__doc__); __name__ is the
method name (same as __func__.__name__); __module__ is the
name of the module the method was defined in, or None if unavailable.
Methods also support accessing (but not setting) the arbitrary function
attributes on the underlying function object.
User-defined method objects may be created when getting an attribute of a
class (perhaps via an instance of that class), if that attribute is a
user-defined function object or a class method object.
When an instance method object is created by retrieving a user-defined
function object from a class via one of its instances, its
__self__ attribute is the instance, and the method object is said
to be bound.  The new method’s __func__ attribute is the original
function object.
When a user-defined method object is created by retrieving another method
object from a class or instance, the behaviour is the same as for a
function object, except that the __func__ attribute of the new
instance is not the original method object but its __func__
attribute.
When an instance method object is created by retrieving a class method
object from a class or instance, its __self__ attribute is the
class itself, and its __func__ attribute is the function object
underlying the class method.
When an instance method object is called, the underlying function
(__func__) is called, inserting the class instance
(__self__) in front of the argument list.  For instance, when
C is a class which contains a definition for a function
f(), and x is an instance of C, calling x.f(1) is
equivalent to calling C.f(x, 1).
When an instance method object is derived from a class method object, the
“class instance” stored in __self__ will actually be the class
itself, so that calling either x.f(1) or C.f(1) is equivalent to
calling f(C,1) where f is the underlying function.
Note that the transformation from function object to instance method
object happens each time the attribute is retrieved from the instance.  In
some cases, a fruitful optimization is to assign the attribute to a local
variable and call that local variable. Also notice that this
transformation only happens for user-defined functions; other callable
objects (and all non-callable objects) are retrieved without
transformation.  It is also important to note that user-defined functions
which are attributes of a class instance are not converted to bound
methods; this only happens when the function is an attribute of the
class.
A function or method which uses the yield statement (see section
The yield statement) is called a generator function.  Such a function, when
called, always returns an iterator object which can be used to execute the
body of the function:  calling the iterator’s iterator.__next__()
method will cause the function to execute until it provides a value
using the yield statement.  When the function executes a
return statement or falls off the end, a StopIteration
exception is raised and the iterator will have reached the end of the set of
values to be returned.
A function or method which is defined using async def is called
a coroutine function.  Such a function, when called, returns a
coroutine object.  It may contain await expressions,
as well as async with and async for statements. See
also the Coroutine Objects section.
A built-in function object is a wrapper around a C function.  Examples of
built-in functions are len() and math.sin() (math is a
standard built-in module). The number and type of the arguments are
determined by the C function. Special read-only attributes:
__doc__ is the function’s documentation string, or None if
unavailable; __name__ is the function’s name; __self__ is
set to None (but see the next item); __module__ is the name of
the module the function was defined in or None if unavailable.
This is really a different disguise of a built-in function, this time containing
an object passed to the C function as an implicit extra argument.  An example of
a built-in method is alist.append(), assuming alist is a list object. In
this case, the special read-only attribute __self__ is set to the object
denoted by alist.
Modules are a basic organizational unit of Python code, and are created by
the import system as invoked either by the
import statement (see import), or by calling
functions such as importlib.import_module() and built-in
__import__().  A module object has a namespace implemented by a
dictionary object (this is the dictionary referenced by the __globals__
attribute of functions defined in the module).  Attribute references are
translated to lookups in this dictionary, e.g., m.x is equivalent to
m.__dict__["x"]. A module object does not contain the code object used
to initialize the module (since it isn’t needed once the initialization is
done).
Attribute assignment updates the module’s namespace dictionary, e.g.,
m.x = 1 is equivalent to m.__dict__["x"] = 1.
Special read-only attribute: __dict__ is the module’s namespace as a
dictionary object.
CPython implementation detail: Because of the way CPython clears module dictionaries, the module
dictionary will be cleared when the module falls out of scope even if the
dictionary still has live references.  To avoid this, copy the dictionary
or keep the module around while using its dictionary directly.
Predefined (writable) attributes: __name__ is the module’s name;
__doc__ is the module’s documentation string, or None if
unavailable; __file__ is the pathname of the file from which the
module was loaded, if it was loaded from a file. The __file__
attribute may be missing for certain types of modules, such as C modules
that are statically linked into the interpreter; for extension modules
loaded dynamically from a shared library, it is the pathname of the shared
library file.
Custom class types are typically created by class definitions (see section
Class definitions).  A class has a namespace implemented by a dictionary object.
Class attribute references are translated to lookups in this dictionary, e.g.,
C.x is translated to C.__dict__["x"] (although there are a number of
hooks which allow for other means of locating attributes). When the attribute
name is not found there, the attribute search continues in the base classes.
This search of the base classes uses the C3 method resolution order which
behaves correctly even in the presence of ‘diamond’ inheritance structures
where there are multiple inheritance paths leading back to a common ancestor.
Additional details on the C3 MRO used by Python can be found in the
documentation accompanying the 2.3 release at
https://www.python.org/download/releases/2.3/mro/.
When a class attribute reference (for class C, say) would yield a
class method object, it is transformed into an instance method object whose
__self__ attributes is C.  When it would yield a static
method object, it is transformed into the object wrapped by the static method
object. See section Implementing Descriptors for another way in which attributes
retrieved from a class may differ from those actually contained in its
__dict__.
Class attribute assignments update the class’s dictionary, never the dictionary
of a base class.
A class object can be called (see above) to yield a class instance (see below).
Special attributes: __name__ is the class name; __module__ is
the module name in which the class was defined; __dict__ is the
dictionary containing the class’s namespace; __bases__ is a
tuple (possibly empty or a singleton) containing the base classes, in the
order of their occurrence in the base class list; __doc__ is the
class’s documentation string, or None if undefined.
A class instance is created by calling a class object (see above).  A class
instance has a namespace implemented as a dictionary which is the first place
in which attribute references are searched.  When an attribute is not found
there, and the instance’s class has an attribute by that name, the search
continues with the class attributes.  If a class attribute is found that is a
user-defined function object, it is transformed into an instance method
object whose __self__ attribute is the instance.  Static method and
class method objects are also transformed; see above under “Classes”.  See
section Implementing Descriptors for another way in which attributes of a class
retrieved via its instances may differ from the objects actually stored in
the class’s __dict__.  If no class attribute is found, and the
object’s class has a __getattr__() method, that is called to satisfy
the lookup.
Attribute assignments and deletions update the instance’s dictionary, never a
class’s dictionary.  If the class has a __setattr__() or
__delattr__() method, this is called instead of updating the instance
dictionary directly.
Class instances can pretend to be numbers, sequences, or mappings if they have
methods with certain special names.  See section Special method names.
Special attributes: __dict__ is the attribute dictionary;
__class__ is the instance’s class.
A file object represents an open file.  Various shortcuts are
available to create file objects: the open() built-in function, and
also os.popen(), os.fdopen(), and the
makefile() method of socket objects (and perhaps by
other functions or methods provided by extension modules).
The objects sys.stdin, sys.stdout and sys.stderr are
initialized to file objects corresponding to the interpreter’s standard
input, output and error streams; they are all open in text mode and
therefore follow the interface defined by the io.TextIOBase
abstract class.
A few types used internally by the interpreter are exposed to the user. Their
definitions may change with future versions of the interpreter, but they are
mentioned here for completeness.
Code objects represent byte-compiled executable Python code, or bytecode.
The difference between a code object and a function object is that the function
object contains an explicit reference to the function’s globals (the module in
which it was defined), while a code object contains no context; also the default
argument values are stored in the function object, not in the code object
(because they represent values calculated at run-time).  Unlike function
objects, code objects are immutable and contain no references (directly or
indirectly) to mutable objects.
Special read-only attributes: co_name gives the function name;
co_argcount is the number of positional arguments (including arguments
with default values); co_nlocals is the number of local variables used
by the function (including arguments); co_varnames is a tuple containing
the names of the local variables (starting with the argument names);
co_cellvars is a tuple containing the names of local variables that are
referenced by nested functions; co_freevars is a tuple containing the
names of free variables; co_code is a string representing the sequence
of bytecode instructions; co_consts is a tuple containing the literals
used by the bytecode; co_names is a tuple containing the names used by
the bytecode; co_filename is the filename from which the code was
compiled; co_firstlineno is the first line number of the function;
co_lnotab is a string encoding the mapping from bytecode offsets to
line numbers (for details see the source code of the interpreter);
co_stacksize is the required stack size (including local variables);
co_flags is an integer encoding a number of flags for the interpreter.
The following flag bits are defined for co_flags: bit 0x04 is set if
the function uses the *arguments syntax to accept an arbitrary number of
positional arguments; bit 0x08 is set if the function uses the
**keywords syntax to accept arbitrary keyword arguments; bit 0x20 is set
if the function is a generator.
Future feature declarations (from __future__ import division) also use bits
in co_flags to indicate whether a code object was compiled with a
particular feature enabled: bit 0x2000 is set if the function was compiled
with future division enabled; bits 0x10 and 0x1000 were used in earlier
versions of Python.
Other bits in co_flags are reserved for internal use.
If a code object represents a function, the first item in co_consts is
the documentation string of the function, or None if undefined.
Frame objects represent execution frames.  They may occur in traceback objects
(see below).
Special read-only attributes: f_back is to the previous stack frame
(towards the caller), or None if this is the bottom stack frame;
f_code is the code object being executed in this frame; f_locals
is the dictionary used to look up local variables; f_globals is used for
global variables; f_builtins is used for built-in (intrinsic) names;
f_lasti gives the precise instruction (this is an index into the
bytecode string of the code object).
Special writable attributes: f_trace, if not None, is a function
called at the start of each source code line (this is used by the debugger);
f_lineno is the current line number of the frame — writing to this
from within a trace function jumps to the given line (only for the bottom-most
frame).  A debugger can implement a Jump command (aka Set Next Statement)
by writing to f_lineno.
Frame objects support one method:
This method clears all references to local variables held by the
frame.  Also, if the frame belonged to a generator, the generator
is finalized.  This helps break reference cycles involving frame
objects (for example when catching an exception and storing its
traceback for later use).
RuntimeError is raised if the frame is currently executing.
New in version 3.4.
Traceback objects represent a stack trace of an exception.  A traceback object
is created when an exception occurs.  When the search for an exception handler
unwinds the execution stack, at each unwound level a traceback object is
inserted in front of the current traceback.  When an exception handler is
entered, the stack trace is made available to the program. (See section
The try statement.) It is accessible as the third item of the
tuple returned by sys.exc_info(). When the program contains no suitable
handler, the stack trace is written (nicely formatted) to the standard error
stream; if the interpreter is interactive, it is also made available to the user
as sys.last_traceback.
Special read-only attributes: tb_next is the next level in the stack
trace (towards the frame where the exception occurred), or None if there is
no next level; tb_frame points to the execution frame of the current
level; tb_lineno gives the line number where the exception occurred;
tb_lasti indicates the precise instruction.  The line number and last
instruction in the traceback may differ from the line number of its frame object
if the exception occurred in a try statement with no matching except
clause or with a finally clause.
Slice objects are used to represent slices for __getitem__()
methods.  They are also created by the built-in slice() function.
Special read-only attributes: start is the lower bound;
stop is the upper bound; step is the step
value; each is None if omitted.  These attributes can have any type.
Slice objects support one method:
This method takes a single integer argument length and computes
information about the slice that the slice object would describe if
applied to a sequence of length items.  It returns a tuple of three
integers; respectively these are the start and stop indices and the
step or stride length of the slice. Missing or out-of-bounds indices
are handled in a manner consistent with regular slices.
A class can implement certain operations that are invoked by special syntax
(such as arithmetic operations or subscripting and slicing) by defining methods
with special names. This is Python’s approach to operator overloading,
allowing classes to define their own behavior with respect to language
operators.  For instance, if a class defines a method named __getitem__(),
and x is an instance of this class, then x[i] is roughly equivalent
to type(x).__getitem__(x, i).  Except where mentioned, attempts to execute an
operation raise an exception when no appropriate method is defined (typically
AttributeError or TypeError).
When implementing a class that emulates any built-in type, it is important that
the emulation only be implemented to the degree that it makes sense for the
object being modelled.  For example, some sequences may work well with retrieval
of individual elements, but extracting a slice may not make sense.  (One example
of this is the NodeList interface in the W3C’s Document
Object Model.)
Called to create a new instance of class cls.  __new__() is a static
method (special-cased so you need not declare it as such) that takes the class
of which an instance was requested as its first argument.  The remaining
arguments are those passed to the object constructor expression (the call to the
class).  The return value of __new__() should be the new object instance
(usually an instance of cls).
Typical implementations create a new instance of the class by invoking the
superclass’s __new__() method using super(currentclass,
cls).__new__(cls[, ...]) with appropriate arguments and then modifying the
newly-created instance as necessary before returning it.
If __new__() returns an instance of cls, then the new instance’s
__init__() method will be invoked like __init__(self[, ...]), where
self is the new instance and the remaining arguments are the same as were
passed to __new__().
If __new__() does not return an instance of cls, then the new instance’s
__init__() method will not be invoked.
__new__() is intended mainly to allow subclasses of immutable types (like
int, str, or tuple) to customize instance creation.  It is also commonly
overridden in custom metaclasses in order to customize class creation.
Called after the instance has been created (by __new__()), but before
it is returned to the caller.  The arguments are those passed to the
class constructor expression.  If a base class has an __init__()
method, the derived class’s __init__() method, if any, must explicitly
call it to ensure proper initialization of the base class part of the
instance; for example: BaseClass.__init__(self, [args...]).
Because __new__() and __init__() work together in constructing
objects (__new__() to create it, and __init__() to customise it),
no non-None value may be returned by __init__(); doing so will
cause a TypeError to be raised at runtime.
Called when the instance is about to be destroyed.  This is also called a
destructor.  If a base class has a __del__() method, the derived class’s
__del__() method, if any, must explicitly call it to ensure proper
deletion of the base class part of the instance.  Note that it is possible
(though not recommended!) for the __del__() method to postpone destruction
of the instance by creating a new reference to it.  It may then be called at a
later time when this new reference is deleted.  It is not guaranteed that
__del__() methods are called for objects that still exist when the
interpreter exits.
Note
del x doesn’t directly call x.__del__() — the former decrements
the reference count for x by one, and the latter is only called when
x‘s reference count reaches zero.  Some common situations that may
prevent the reference count of an object from going to zero include:
circular references between objects (e.g., a doubly-linked list or a tree
data structure with parent and child pointers); a reference to the object
on the stack frame of a function that caught an exception (the traceback
stored in sys.exc_info()[2] keeps the stack frame alive); or a
reference to the object on the stack frame that raised an unhandled
exception in interactive mode (the traceback stored in
sys.last_traceback keeps the stack frame alive).  The first situation
can only be remedied by explicitly breaking the cycles; the second can be
resolved by freeing the reference to the traceback object when it is no
longer useful, and the third can be resolved by storing None in
sys.last_traceback.
Circular references which are garbage are detected and cleaned up when
the cyclic garbage collector is enabled (it’s on by default). Refer to the
documentation for the gc module for more information about this
topic.
Warning
Due to the precarious circumstances under which __del__() methods are
invoked, exceptions that occur during their execution are ignored, and a warning
is printed to sys.stderr instead.  Also, when __del__() is invoked in
response to a module being deleted (e.g., when execution of the program is
done), other globals referenced by the __del__() method may already have
been deleted or in the process of being torn down (e.g. the import
machinery shutting down).  For this reason, __del__() methods
should do the absolute
minimum needed to maintain external invariants.  Starting with version 1.5,
Python guarantees that globals whose name begins with a single underscore are
deleted from their module before other globals are deleted; if no other
references to such globals exist, this may help in assuring that imported
modules are still available at the time when the __del__() method is
called.
Called by the repr() built-in function to compute the “official” string
representation of an object.  If at all possible, this should look like a
valid Python expression that could be used to recreate an object with the
same value (given an appropriate environment).  If this is not possible, a
string of the form <...some useful description...> should be returned.
The return value must be a string object. If a class defines __repr__()
but not __str__(), then __repr__() is also used when an
“informal” string representation of instances of that class is required.
This is typically used for debugging, so it is important that the representation
is information-rich and unambiguous.
Called by str(object) and the built-in functions
format() and print() to compute the “informal” or nicely
printable string representation of an object.  The return value must be a
string object.
This method differs from object.__repr__() in that there is no
expectation that __str__() return a valid Python expression: a more
convenient or concise representation can be used.
The default implementation defined by the built-in type object
calls object.__repr__().
Called by bytes() to compute a byte-string representation of an
object. This should return a bytes object.
Called by the format() built-in function (and by extension, the
str.format() method of class str) to produce a “formatted”
string representation of an object. The format_spec argument is
a string that contains a description of the formatting options desired.
The interpretation of the format_spec argument is up to the type
implementing __format__(), however most classes will either
delegate formatting to one of the built-in types, or use a similar
formatting option syntax.
See Format Specification Mini-Language for a description of the standard formatting syntax.
The return value must be a string object.
Changed in version 3.4: The __format__ method of object itself raises a TypeError
if passed any non-empty string.
These are the so-called “rich comparison” methods. The correspondence between
operator symbols and method names is as follows: x<y calls x.__lt__(y),
x<=y calls x.__le__(y), x==y calls x.__eq__(y), x!=y calls
x.__ne__(y), x>y calls x.__gt__(y), and x>=y calls
x.__ge__(y).
A rich comparison method may return the singleton NotImplemented if it does
not implement the operation for a given pair of arguments. By convention,
False and True are returned for a successful comparison. However, these
methods can return any value, so if the comparison operator is used in a Boolean
context (e.g., in the condition of an if statement), Python will call
bool() on the value to determine if the result is true or false.
By default, __ne__() delegates to __eq__() and
inverts the result unless it is NotImplemented.  There are no other
implied relationships among the comparison operators, for example,
the truth of (x<y or x==y) does not imply x<=y.
To automatically generate ordering operations from a single root operation,
see functools.total_ordering().
See the paragraph on __hash__() for
some important notes on creating hashable objects which support
custom comparison operations and are usable as dictionary keys.
There are no swapped-argument versions of these methods (to be used when the
left argument does not support the operation but the right argument does);
rather, __lt__() and __gt__() are each other’s reflection,
__le__() and __ge__() are each other’s reflection, and
__eq__() and __ne__() are their own reflection.
If the operands are of different types, and right operand’s type is
a direct or indirect subclass of the left operand’s type,
the reflected method of the right operand has priority, otherwise
the left operand’s method has priority.  Virtual subclassing is
not considered.
Called by built-in function hash() and for operations on members of
hashed collections including set, frozenset, and
dict.  __hash__() should return an integer.  The only
required property is that objects which compare equal have the same hash
value; it is advised to somehow mix together (e.g. using exclusive or) the
hash values for the components of the object that also play a part in
comparison of objects.
Note
hash() truncates the value returned from an object’s custom
__hash__() method to the size of a Py_ssize_t.  This is
typically 8 bytes on 64-bit builds and 4 bytes on 32-bit builds.  If an
object’s   __hash__() must interoperate on builds of different bit
sizes, be sure to check the width on all supported builds.  An easy way
to do this is with
python -c "import sys; print(sys.hash_info.width)".
If a class does not define an __eq__() method it should not define a
__hash__() operation either; if it defines __eq__() but not
__hash__(), its instances will not be usable as items in hashable
collections.  If a class defines mutable objects and implements an
__eq__() method, it should not implement __hash__(), since the
implementation of hashable collections requires that a key’s hash value is
immutable (if the object’s hash value changes, it will be in the wrong hash
bucket).
User-defined classes have __eq__() and __hash__() methods
by default; with them, all objects compare unequal (except with themselves)
and x.__hash__() returns an appropriate value such that x == y
implies both that x is y and hash(x) == hash(y).
A class that overrides __eq__() and does not define __hash__()
will have its __hash__() implicitly set to None.  When the
__hash__() method of a class is None, instances of the class will
raise an appropriate TypeError when a program attempts to retrieve
their hash value, and will also be correctly identified as unhashable when
checking isinstance(obj, collections.Hashable).
If a class that overrides __eq__() needs to retain the implementation
of __hash__() from a parent class, the interpreter must be told this
explicitly by setting __hash__ = <ParentClass>.__hash__.
If a class that does not override __eq__() wishes to suppress hash
support, it should include __hash__ = None in the class definition.
A class which defines its own __hash__() that explicitly raises
a TypeError would be incorrectly identified as hashable by
an isinstance(obj, collections.Hashable) call.
Note
By default, the __hash__() values of str, bytes and datetime
objects are “salted” with an unpredictable random value.  Although they
remain constant within an individual Python process, they are not
predictable between repeated invocations of Python.
This is intended to provide protection against a denial-of-service caused
by carefully-chosen inputs that exploit the worst case performance of a
dict insertion, O(n^2) complexity.  See
http://www.ocert.org/advisories/ocert-2011-003.html for details.
Changing hash values affects the iteration order of dicts, sets and
other mappings.  Python has never made guarantees about this ordering
(and it typically varies between 32-bit and 64-bit builds).
See also PYTHONHASHSEED.
Changed in version 3.3: Hash randomization is enabled by default.
Called to implement truth value testing and the built-in operation
bool(); should return False or True.  When this method is not
defined, __len__() is called, if it is defined, and the object is
considered true if its result is nonzero.  If a class defines neither
__len__() nor __bool__(), all its instances are considered
true.
The following methods can be defined to customize the meaning of attribute
access (use of, assignment to, or deletion of x.name) for class instances.
Called when an attribute lookup has not found the attribute in the usual places
(i.e. it is not an instance attribute nor is it found in the class tree for
self).  name is the attribute name. This method should return the
(computed) attribute value or raise an AttributeError exception.
Note that if the attribute is found through the normal mechanism,
__getattr__() is not called.  (This is an intentional asymmetry between
__getattr__() and __setattr__().) This is done both for efficiency
reasons and because otherwise __getattr__() would have no way to access
other attributes of the instance.  Note that at least for instance variables,
you can fake total control by not inserting any values in the instance attribute
dictionary (but instead inserting them in another object).  See the
__getattribute__() method below for a way to actually get total control
over attribute access.
Called unconditionally to implement attribute accesses for instances of the
class. If the class also defines __getattr__(), the latter will not be
called unless __getattribute__() either calls it explicitly or raises an
AttributeError. This method should return the (computed) attribute value
or raise an AttributeError exception. In order to avoid infinite
recursion in this method, its implementation should always call the base class
method with the same name to access any attributes it needs, for example,
object.__getattribute__(self, name).
Note
This method may still be bypassed when looking up special methods as the
result of implicit invocation via language syntax or built-in functions.
See Special method lookup.
Called when an attribute assignment is attempted.  This is called instead of
the normal mechanism (i.e. store the value in the instance dictionary).
name is the attribute name, value is the value to be assigned to it.
If __setattr__() wants to assign to an instance attribute, it should
call the base class method with the same name, for example,
object.__setattr__(self, name, value).
Like __setattr__() but for attribute deletion instead of assignment.  This
should only be implemented if del obj.name is meaningful for the object.
Called when dir() is called on the object. A sequence must be
returned. dir() converts the returned sequence to a list and sorts it.
The following methods only apply when an instance of the class containing the
method (a so-called descriptor class) appears in an owner class (the
descriptor must be in either the owner’s class dictionary or in the class
dictionary for one of its parents).  In the examples below, “the attribute”
refers to the attribute whose name is the key of the property in the owner
class’ __dict__.
Called to get the attribute of the owner class (class attribute access) or of an
instance of that class (instance attribute access). owner is always the owner
class, while instance is the instance that the attribute was accessed through,
or None when the attribute is accessed through the owner.  This method
should return the (computed) attribute value or raise an AttributeError
exception.
Called to set the attribute on an instance instance of the owner class to a
new value, value.
Called to delete the attribute on an instance instance of the owner class.
The attribute __objclass__ is interpreted by the inspect module
as specifying the class where this object was defined (setting this
appropriately can assist in runtime introspection of dynamic class attributes).
For callables, it may indicate that an instance of the given type (or a
subclass) is expected or required as the first positional argument (for example,
CPython sets this attribute for unbound methods that are implemented in C).
In general, a descriptor is an object attribute with “binding behavior”, one
whose attribute access has been overridden by methods in the descriptor
protocol:  __get__(), __set__(), and __delete__(). If any of
those methods are defined for an object, it is said to be a descriptor.
The default behavior for attribute access is to get, set, or delete the
attribute from an object’s dictionary. For instance, a.x has a lookup chain
starting with a.__dict__['x'], then type(a).__dict__['x'], and
continuing through the base classes of type(a) excluding metaclasses.
However, if the looked-up value is an object defining one of the descriptor
methods, then Python may override the default behavior and invoke the descriptor
method instead.  Where this occurs in the precedence chain depends on which
descriptor methods were defined and how they were called.
The starting point for descriptor invocation is a binding, a.x. How the
arguments are assembled depends on a:
For instance bindings, the precedence of descriptor invocation depends on the
which descriptor methods are defined.  A descriptor can define any combination
of __get__(), __set__() and __delete__().  If it does not
define __get__(), then accessing the attribute will return the descriptor
object itself unless there is a value in the object’s instance dictionary.  If
the descriptor defines __set__() and/or __delete__(), it is a data
descriptor; if it defines neither, it is a non-data descriptor.  Normally, data
descriptors define both __get__() and __set__(), while non-data
descriptors have just the __get__() method.  Data descriptors with
__set__() and __get__() defined always override a redefinition in an
instance dictionary.  In contrast, non-data descriptors can be overridden by
instances.
Python methods (including staticmethod() and classmethod()) are
implemented as non-data descriptors.  Accordingly, instances can redefine and
override methods.  This allows individual instances to acquire behaviors that
differ from other instances of the same class.
The property() function is implemented as a data descriptor. Accordingly,
instances cannot override the behavior of a property.
By default, instances of classes have a dictionary for attribute storage.  This
wastes space for objects having very few instance variables.  The space
consumption can become acute when creating large numbers of instances.
The default can be overridden by defining __slots__ in a class definition.
The __slots__ declaration takes a sequence of instance variables and reserves
just enough space in each instance to hold a value for each variable.  Space is
saved because __dict__ is not created for each instance.
This class variable can be assigned a string, iterable, or sequence of
strings with variable names used by instances.  __slots__ reserves space
for the declared variables and prevents the automatic creation of __dict__
and __weakref__ for each instance.
By default, classes are constructed using type(). The class body is
executed in a new namespace and the class name is bound locally to the
result of type(name, bases, namespace).
The class creation process can be customised by passing the metaclass
keyword argument in the class definition line, or by inheriting from an
existing class that included such an argument. In the following example,
both MyClass and MySubclass are instances of Meta:
Any other keyword arguments that are specified in the class definition are
passed through to all metaclass operations described below.
When a class definition is executed, the following steps occur:
The appropriate metaclass for a class definition is determined as follows:
The most derived metaclass is selected from the explicitly specified
metaclass (if any) and the metaclasses (i.e. type(cls)) of all specified
base classes. The most derived metaclass is one which is a subtype of all
of these candidate metaclasses. If none of the candidate metaclasses meets
that criterion, then the class definition will fail with TypeError.
Once the appropriate metaclass has been identified, then the class namespace
is prepared. If the metaclass has a __prepare__ attribute, it is called
as namespace = metaclass.__prepare__(name, bases, **kwds) (where the
additional keyword arguments, if any, come from the class definition).
If the metaclass has no __prepare__ attribute, then the class namespace
is initialised as an empty dict() instance.
See also
The class body is executed (approximately) as
exec(body, globals(), namespace). The key difference from a normal
call to exec() is that lexical scoping allows the class body (including
any methods) to reference names from the current and outer scopes when the
class definition occurs inside a function.
However, even when the class definition occurs inside the function, methods
defined inside the class still cannot see names defined at the class scope.
Class variables must be accessed through the first parameter of instance or
class methods, and cannot be accessed at all from static methods.
Once the class namespace has been populated by executing the class body,
the class object is created by calling
metaclass(name, bases, namespace, **kwds) (the additional keywords
passed here are the same as those passed to __prepare__).
This class object is the one that will be referenced by the zero-argument
form of super(). __class__ is an implicit closure reference
created by the compiler if any methods in a class body refer to either
__class__ or super. This allows the zero argument form of
super() to correctly identify the class being defined based on
lexical scoping, while the class or instance that was used to make the
current call is identified based on the first argument passed to the method.
After the class object is created, it is passed to the class decorators
included in the class definition (if any) and the resulting object is bound
in the local namespace as the defined class.
When a new class is created by type.__new__, the object provided as the
namespace parameter is copied to a standard Python dictionary and the original
object is discarded. The new copy becomes the __dict__ attribute
of the class object.
See also
The potential uses for metaclasses are boundless. Some ideas that have been
explored include logging, interface checking, automatic delegation, automatic
property creation, proxies, frameworks, and automatic resource
locking/synchronization.
Here is an example of a metaclass that uses an collections.OrderedDict
to remember the order that class variables are defined:
When the class definition for A gets executed, the process begins with
calling the metaclass’s __prepare__() method which returns an empty
collections.OrderedDict.  That mapping records the methods and
attributes of A as they are defined within the body of the class statement.
Once those definitions are executed, the ordered dictionary is fully populated
and the metaclass’s __new__() method gets invoked.  That method builds
the new type and it saves the ordered dictionary keys in an attribute
called members.
The following methods are used to override the default behavior of the
isinstance() and issubclass() built-in functions.
In particular, the metaclass abc.ABCMeta implements these methods in
order to allow the addition of Abstract Base Classes (ABCs) as “virtual base
classes” to any class or type (including built-in types), including other
ABCs.
Return true if instance should be considered a (direct or indirect)
instance of class. If defined, called to implement isinstance(instance,
class).
Return true if subclass should be considered a (direct or indirect)
subclass of class.  If defined, called to implement issubclass(subclass,
class).
Note that these methods are looked up on the type (metaclass) of a class.  They
cannot be defined as class methods in the actual class.  This is consistent with
the lookup of special methods that are called on instances, only in this
case the instance is itself a class.
See also
Called when the instance is “called” as a function; if this method is defined,
x(arg1, arg2, ...) is a shorthand for x.__call__(arg1, arg2, ...).
The following methods can be defined to implement container objects.  Containers
usually are sequences (such as lists or tuples) or mappings (like dictionaries),
but can represent other containers as well.  The first set of methods is used
either to emulate a sequence or to emulate a mapping; the difference is that for
a sequence, the allowable keys should be the integers k for which 0 <= k <
N where N is the length of the sequence, or slice objects, which define a
range of items.  It is also recommended that mappings provide the methods
keys(), values(), items(), get(), clear(),
setdefault(), pop(), popitem(), copy(), and
update() behaving similar to those for Python’s standard dictionary
objects.  The collections module provides a
MutableMapping
abstract base class to help create those methods from a base set of
__getitem__(), __setitem__(), __delitem__(), and keys().
Mutable sequences should provide methods append(), count(),
index(), extend(), insert(), pop(), remove(),
reverse() and sort(), like Python standard list objects.  Finally,
sequence types should implement addition (meaning concatenation) and
multiplication (meaning repetition) by defining the methods __add__(),
__radd__(), __iadd__(), __mul__(), __rmul__() and
__imul__() described below; they should not define other numerical
operators.  It is recommended that both mappings and sequences implement the
__contains__() method to allow efficient use of the in operator; for
mappings, in should search the mapping’s keys; for sequences, it should
search through the values.  It is further recommended that both mappings and
sequences implement the __iter__() method to allow efficient iteration
through the container; for mappings, __iter__() should be the same as
keys(); for sequences, it should iterate through the values.
Called to implement the built-in function len().  Should return the length
of the object, an integer >= 0.  Also, an object that doesn’t define a
__bool__() method and whose __len__() method returns zero is
considered to be false in a Boolean context.
Called to implement operator.length_hint(). Should return an estimated
length for the object (which may be greater or less than the actual length).
The length must be an integer >= 0. This method is purely an
optimization and is never required for correctness.
New in version 3.4.
Note
Slicing is done exclusively with the following three methods.  A call like
is translated to
and so forth.  Missing slice items are always filled in with None.
Called to implement evaluation of self[key]. For sequence types, the
accepted keys should be integers and slice objects.  Note that the special
interpretation of negative indexes (if the class wishes to emulate a sequence
type) is up to the __getitem__() method. If key is of an inappropriate
type, TypeError may be raised; if of a value outside the set of indexes
for the sequence (after any special interpretation of negative values),
IndexError should be raised. For mapping types, if key is missing (not
in the container), KeyError should be raised.
Note
for loops expect that an IndexError will be raised for illegal
indexes to allow proper detection of the end of the sequence.
Called by dict.__getitem__() to implement self[key] for dict subclasses
when key is not in the dictionary.
Called to implement assignment to self[key].  Same note as for
__getitem__().  This should only be implemented for mappings if the
objects support changes to the values for keys, or if new keys can be added, or
for sequences if elements can be replaced.  The same exceptions should be raised
for improper key values as for the __getitem__() method.
Called to implement deletion of self[key].  Same note as for
__getitem__().  This should only be implemented for mappings if the
objects support removal of keys, or for sequences if elements can be removed
from the sequence.  The same exceptions should be raised for improper key
values as for the __getitem__() method.
This method is called when an iterator is required for a container. This method
should return a new iterator object that can iterate over all the objects in the
container.  For mappings, it should iterate over the keys of the container.
Iterator objects also need to implement this method; they are required to return
themselves.  For more information on iterator objects, see Iterator Types.
Called (if present) by the reversed() built-in to implement
reverse iteration.  It should return a new iterator object that iterates
over all the objects in the container in reverse order.
If the __reversed__() method is not provided, the reversed()
built-in will fall back to using the sequence protocol (__len__() and
__getitem__()).  Objects that support the sequence protocol should
only provide __reversed__() if they can provide an implementation
that is more efficient than the one provided by reversed().
The membership test operators (in and not in) are normally
implemented as an iteration through a sequence.  However, container objects can
supply the following special method with a more efficient implementation, which
also does not require the object be a sequence.
Called to implement membership test operators.  Should return true if item
is in self, false otherwise.  For mapping objects, this should consider the
keys of the mapping rather than the values or the key-item pairs.
For objects that don’t define __contains__(), the membership test first
tries iteration via __iter__(), then the old sequence iteration
protocol via __getitem__(), see this section in the language
reference.
The following methods can be defined to emulate numeric objects. Methods
corresponding to operations that are not supported by the particular kind of
number implemented (e.g., bitwise operations for non-integral numbers) should be
left undefined.
These methods are called to implement the binary arithmetic operations
(+, -, *, @, /, //, %, divmod(),
pow(), **, <<, >>, &, ^, |).  For instance, to
evaluate the expression x + y, where x is an instance of a class that
has an __add__() method, x.__add__(y) is called.  The
__divmod__() method should be the equivalent to using
__floordiv__() and __mod__(); it should not be related to
__truediv__().  Note that __pow__() should be defined to accept
an optional third argument if the ternary version of the built-in pow()
function is to be supported.
If one of those methods does not support the operation with the supplied
arguments, it should return NotImplemented.
These methods are called to implement the binary arithmetic operations
(+, -, *, @, /, //, %, divmod(),
pow(), **, <<, >>, &, ^, |) with reflected
(swapped) operands.  These functions are only called if the left operand does
not support the corresponding operation and the operands are of different
types. [2] For instance, to evaluate the expression x - y, where y is
an instance of a class that has an __rsub__() method, y.__rsub__(x)
is called if x.__sub__(y) returns NotImplemented.
Note that ternary pow() will not try calling __rpow__() (the
coercion rules would become too complicated).
Note
If the right operand’s type is a subclass of the left operand’s type and that
subclass provides the reflected method for the operation, this method will be
called before the left operand’s non-reflected method.  This behavior allows
subclasses to override their ancestors’ operations.
These methods are called to implement the augmented arithmetic assignments
(+=, -=, *=, @=, /=, //=, %=, **=, <<=,
>>=, &=, ^=, |=).  These methods should attempt to do the
operation in-place (modifying self) and return the result (which could be,
but does not have to be, self).  If a specific method is not defined, the
augmented assignment falls back to the normal methods.  For instance, if x
is an instance of a class with an __iadd__() method, x += y is
equivalent to x = x.__iadd__(y) . Otherwise, x.__add__(y) and
y.__radd__(x) are considered, as with the evaluation of x + y. In
certain situations, augmented assignment can result in unexpected errors (see
Why does a_tuple[i] += [‘item’] raise an exception when the addition works?), but this behavior is in fact
part of the data model.
Called to implement the unary arithmetic operations (-, +, abs()
and ~).
Called to implement the built-in functions complex(),
int(), float() and round().  Should return a value
of the appropriate type.
Called to implement operator.index(), and whenever Python needs to
losslessly convert the numeric object to an integer object (such as in
slicing, or in the built-in bin(), hex() and oct()
functions). Presence of this method indicates that the numeric object is
an integer type.  Must return an integer.
Note
In order to have a coherent integer type class, when __index__() is
defined __int__() should also be defined, and both should return
the same value.
A context manager is an object that defines the runtime context to be
established when executing a with statement. The context manager
handles the entry into, and the exit from, the desired runtime context for the
execution of the block of code.  Context managers are normally invoked using the
with statement (described in section The with statement), but can also be
used by directly invoking their methods.
Typical uses of context managers include saving and restoring various kinds of
global state, locking and unlocking resources, closing opened files, etc.
For more information on context managers, see Context Manager Types.
Enter the runtime context related to this object. The with statement
will bind this method’s return value to the target(s) specified in the
as clause of the statement, if any.
Exit the runtime context related to this object. The parameters describe the
exception that caused the context to be exited. If the context was exited
without an exception, all three arguments will be None.
If an exception is supplied, and the method wishes to suppress the exception
(i.e., prevent it from being propagated), it should return a true value.
Otherwise, the exception will be processed normally upon exit from this method.
Note that __exit__() methods should not reraise the passed-in exception;
this is the caller’s responsibility.
See also
For custom classes, implicit invocations of special methods are only guaranteed
to work correctly if defined on an object’s type, not in the object’s instance
dictionary.  That behaviour is the reason why the following code raises an
exception:
The rationale behind this behaviour lies with a number of special methods such
as __hash__() and __repr__() that are implemented by all objects,
including type objects. If the implicit lookup of these methods used the
conventional lookup process, they would fail when invoked on the type object
itself:
Incorrectly attempting to invoke an unbound method of a class in this way is
sometimes referred to as ‘metaclass confusion’, and is avoided by bypassing
the instance when looking up special methods:
In addition to bypassing any instance attributes in the interest of
correctness, implicit special method lookup generally also bypasses the
__getattribute__() method even of the object’s metaclass:
Bypassing the __getattribute__() machinery in this fashion
provides significant scope for speed optimisations within the
interpreter, at the cost of some flexibility in the handling of
special methods (the special method must be set on the class
object itself in order to be consistently invoked by the interpreter).
An awaitable object generally implements an __await__() method.
Coroutine objects returned from async def functions
are awaitable.
Note
The generator iterator objects returned from generators
decorated with types.coroutine() or asyncio.coroutine()
are also awaitable, but they do not implement __await__().
Must return an iterator.  Should be used to implement
awaitable objects.  For instance, asyncio.Future implements
this method to be compatible with the await expression.
New in version 3.5.
See also
PEP 492 for additional information about awaitable objects.
Coroutine objects are awaitable objects.
A coroutine’s execution can be controlled by calling __await__() and
iterating over the result.  When the coroutine has finished executing and
returns, the iterator raises StopIteration, and the exception’s
value attribute holds the return value.  If the
coroutine raises an exception, it is propagated by the iterator.  Coroutines
should not directly raise unhandled StopIteration exceptions.
Coroutines also have the methods listed below, which are analogous to
those of generators (see Generator-iterator methods).  However, unlike
generators, coroutines do not directly support iteration.
Changed in version 3.5.2: It is a RuntimeError to await on a coroutine more than once.
Starts or resumes execution of the coroutine.  If value is None,
this is equivalent to advancing the iterator returned by
__await__().  If value is not None, this method delegates
to the send() method of the iterator that caused
the coroutine to suspend.  The result (return value,
StopIteration, or other exception) is the same as when
iterating over the __await__() return value, described above.
Raises the specified exception in the coroutine.  This method delegates
to the throw() method of the iterator that caused
the coroutine to suspend, if it has such a method.  Otherwise,
the exception is raised at the suspension point.  The result
(return value, StopIteration, or other exception) is the same as
when iterating over the __await__() return value, described
above.  If the exception is not caught in the coroutine, it propagates
back to the caller.
Causes the coroutine to clean itself up and exit.  If the coroutine
is suspended, this method first delegates to the close()
method of the iterator that caused the coroutine to suspend, if it
has such a method.  Then it raises GeneratorExit at the
suspension point, causing the coroutine to immediately clean itself up.
Finally, the coroutine is marked as having finished executing, even if
it was never started.
Coroutine objects are automatically closed using the above process when
they are about to be destroyed.
An asynchronous iterable is able to call asynchronous code in its
__aiter__ implementation, and an asynchronous iterator can call
asynchronous code in its __anext__ method.
Asynchronous iterators can be used in an async for statement.
Must return an asynchronous iterator object.
Must return an awaitable resulting in a next value of the iterator.  Should
raise a StopAsyncIteration error when the iteration is over.
An example of an asynchronous iterable object:
New in version 3.5.
Note
Changed in version 3.5.2: Starting with CPython 3.5.2, __aiter__ can directly return
asynchronous iterators.  Returning
an awaitable object will result in a
PendingDeprecationWarning.
The recommended way of writing backwards compatible code in
CPython 3.5.x is to continue returning awaitables from
__aiter__.  If you want to avoid the PendingDeprecationWarning
and keep the code backwards compatible, the following decorator
can be used:
Example:
Starting with CPython 3.6, the PendingDeprecationWarning
will be replaced with the DeprecationWarning.
In CPython 3.7, returning an awaitable from __aiter__ will
result in a RuntimeError.
An asynchronous context manager is a context manager that is able to
suspend execution in its __aenter__ and __aexit__ methods.
Asynchronous context managers can be used in an async with statement.
This method is semantically similar to the __enter__(), with only
difference that it must return an awaitable.
This method is semantically similar to the __exit__(), with only
difference that it must return an awaitable.
An example of an asynchronous context manager class:
New in version 3.5.
Footnotes
2. Lexical analysis
4. Execution model

    Enter search terms or a module, class or function name.
    

